id,framework,subcategory,ai_security_control,description,priority,category,implementation_effort,business_impact,threat_vector,mitigation_strategy,compliance_requirement,createdAt,updatedAt
ai-001,OWASP Top 10 for LLM Applications,LLM01:2025 Prompt Injection,Implement input validation and sanitization,"Validate and sanitize all user inputs to prevent prompt injection attacks that can manipulate LLM behavior",Critical,Input Validation,High,Critical,Prompt Injection,"Input validation, sanitization, and prompt engineering best practices",OWASP LLM Top 10,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-002,OWASP Top 10 for LLM Applications,LLM02:2025 Sensitive Information Disclosure,Implement data classification and access controls,"Classify sensitive data and implement proper access controls to prevent unauthorized disclosure of sensitive information",High,Data Protection,Medium,High,Data Leakage,"Data classification, access controls, and output filtering",OWASP LLM Top 10,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-003,OWASP Top 10 for LLM Applications,LLM03:2025 Supply Chain,Implement supply chain security controls,"Secure the LLM supply chain by validating models, dependencies, and third-party components",High,Supply Chain Security,High,High,Supply Chain Attacks,"Model validation, dependency scanning, and secure procurement",OWASP LLM Top 10,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-004,OWASP Top 10 for LLM Applications,LLM04:2025 Data and Model Poisoning,Implement training data validation,"Validate and monitor training data to prevent poisoning attacks that can compromise model integrity",Critical,Model Security,Very High,Critical,Data Poisoning,"Training data validation, model monitoring, and adversarial testing",OWASP LLM Top 10,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-005,OWASP Top 10 for LLM Applications,LLM05:2025 Improper Output Handling,Implement output validation and sanitization,"Validate and sanitize LLM outputs to prevent injection attacks and ensure safe content delivery",High,Output Security,Medium,High,Output Injection,"Output validation, content filtering, and safe rendering",OWASP LLM Top 10,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-006,OWASP Top 10 for LLM Applications,LLM06:2025 Excessive Agency,Implement agency controls and monitoring,"Control and monitor LLM agency to prevent excessive autonomous actions that could cause harm",Medium,Agent Control,High,Medium,Excessive Autonomy,"Agent boundaries, monitoring, and human oversight",OWASP LLM Top 10,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-007,OWASP Top 10 for LLM Applications,LLM07:2025 System Prompt Leakage,Implement prompt protection mechanisms,"Protect system prompts from leakage to prevent attackers from understanding and manipulating system behavior",Medium,Prompt Security,Low,Medium,Information Disclosure,"Prompt obfuscation, access controls, and monitoring",OWASP LLM Top 10,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-008,OWASP Top 10 for LLM Applications,LLM08:2025 Vector and Embedding Weaknesses,Implement secure vector operations,"Secure vector and embedding operations to prevent attacks on semantic search and retrieval systems",High,Vector Security,Medium,High,Vector Attacks,"Secure embeddings, vector validation, and access controls",OWASP LLM Top 10,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-009,OWASP Top 10 for LLM Applications,LLM09:2025 Misinformation,Implement content verification and fact-checking,"Implement mechanisms to detect and prevent misinformation generation by LLMs",Critical,Content Security,High,Critical,Misinformation,"Content verification, fact-checking, and source validation",OWASP LLM Top 10,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-010,OWASP Top 10 for LLM Applications,LLM10:2025 Unbounded Consumption,Implement resource consumption controls,"Control and limit resource consumption to prevent denial of service and cost escalation",Medium,Resource Management,Low,Medium,Resource Exhaustion,"Rate limiting, resource monitoring, and cost controls",OWASP LLM Top 10,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-011,CSA MAESTRO Agentic AI,Agent Security,Implement agent authentication and authorization,"Establish strong authentication and authorization mechanisms for AI agents to prevent unauthorized access",High,Agent Security,Medium,High,Unauthorized Access,"Multi-factor authentication, role-based access control, and agent identity management",CSA MAESTRO,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-012,CSA MAESTRO Agentic AI,Agent Security,Implement agent communication security,"Secure inter-agent communication to prevent eavesdropping and tampering",High,Communication Security,Medium,High,Communication Attacks,"Encrypted communication, message integrity, and secure protocols",CSA MAESTRO,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-013,CSA MAESTRO Agentic AI,Multi-Agent Coordination,Implement coordination security controls,"Secure multi-agent coordination to prevent conflicts and ensure safe collaboration",Medium,Coordination Security,High,Medium,Coordination Failures,"Conflict resolution, coordination protocols, and safety mechanisms",CSA MAESTRO,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-014,CSA MAESTRO Agentic AI,Multi-Agent Coordination,Implement distributed decision making security,"Secure distributed decision making processes to prevent manipulation and ensure consensus",High,Decision Security,Very High,High,Decision Manipulation,"Consensus mechanisms, decision validation, and audit trails",CSA MAESTRO,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-015,CSA MAESTRO Agentic AI,Autonomous Decision Making,Implement decision monitoring and oversight,"Monitor autonomous decisions to ensure they align with organizational policies and values",High,Decision Oversight,Medium,High,Unsafe Decisions,"Decision logging, policy enforcement, and human oversight",CSA MAESTRO,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-016,CSA MAESTRO Agentic AI,Autonomous Decision Making,Implement decision rollback mechanisms,"Implement mechanisms to rollback or correct harmful autonomous decisions",Medium,Decision Recovery,High,Medium,Decision Errors,"Decision versioning, rollback procedures, and correction mechanisms",CSA MAESTRO,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-017,CSA MAESTRO Agentic AI,Agent Communication Security,Implement secure agent discovery,"Secure agent discovery mechanisms to prevent malicious agent infiltration",Medium,Agent Discovery,Low,Medium,Malicious Agents,"Agent registry security, identity verification, and reputation systems",CSA MAESTRO,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-018,CSA MAESTRO Agentic AI,Agent Communication Security,Implement message integrity verification,"Verify message integrity in agent communications to prevent tampering",High,Message Security,Low,High,Message Tampering,"Digital signatures, message authentication, and integrity checks",CSA MAESTRO,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-019,NIST AI RMF,Govern,Establish AI governance framework,"Develop comprehensive governance framework for AI system development and deployment",High,Governance,High,High,Governance Gaps,"Policy development, oversight structures, and accountability mechanisms",NIST AI RMF,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-020,NIST AI RMF,Govern,Implement AI risk management policies,"Establish policies and procedures for managing AI-related risks throughout the system lifecycle",High,Risk Management,Medium,High,Risk Exposure,"Risk assessment procedures, mitigation strategies, and monitoring systems",NIST AI RMF,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-021,NIST AI RMF,Map,Conduct AI system mapping,"Map AI systems and their components to understand dependencies and potential failure points",Medium,System Mapping,Medium,Medium,System Complexity,"System documentation, dependency mapping, and impact analysis",NIST AI RMF,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-022,NIST AI RMF,Map,Identify AI system boundaries,"Clearly define AI system boundaries and interfaces to understand security perimeters",Medium,Boundary Definition,Low,Medium,Boundary Confusion,"Interface documentation, boundary controls, and access management",NIST AI RMF,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-023,NIST AI RMF,Measure,Implement AI performance monitoring,"Monitor AI system performance to detect anomalies and ensure reliable operation",High,Performance Monitoring,Medium,High,Performance Degradation,"Performance metrics, anomaly detection, and alerting systems",NIST AI RMF,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-024,NIST AI RMF,Measure,Conduct AI bias testing,"Test AI systems for bias and fairness to ensure equitable outcomes",High,Bias Testing,High,High,Algorithmic Bias,"Bias testing frameworks, fairness metrics, and corrective measures",NIST AI RMF,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-025,NIST AI RMF,Manage,Implement AI incident response,"Develop incident response procedures specifically for AI system failures and security breaches",High,Incident Response,Medium,High,Incident Impact,"Response procedures, communication plans, and recovery processes",NIST AI RMF,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-026,NIST AI RMF,Manage,Establish AI system maintenance procedures,"Implement regular maintenance and updates for AI systems to ensure security and performance",Medium,System Maintenance,Low,Medium,System Decay,"Maintenance schedules, update procedures, and change management",NIST AI RMF,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-027,MITRE ATLAS,Adversarial Tactics,Implement adversarial training,"Train AI models against adversarial examples to improve robustness",High,Adversarial Defense,Very High,High,Adversarial Attacks,"Adversarial training, robust optimization, and defensive distillation",MITRE ATLAS,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-028,MITRE ATLAS,Adversarial Tactics,Implement input preprocessing defenses,"Preprocess inputs to detect and filter adversarial examples before model processing",Medium,Input Defense,Medium,Medium,Adversarial Inputs,"Input sanitization, anomaly detection, and preprocessing filters",MITRE ATLAS,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-029,MITRE ATLAS,Attack Patterns,Implement model extraction defenses,"Protect AI models from extraction attacks that could reveal proprietary information",High,Model Protection,High,High,Model Theft,"Model obfuscation, access controls, and watermarking",MITRE ATLAS,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-030,MITRE ATLAS,Attack Patterns,Implement membership inference defenses,"Protect against membership inference attacks that could reveal training data information",Medium,Privacy Protection,High,Medium,Privacy Leakage,"Differential privacy, data anonymization, and membership testing",MITRE ATLAS,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-031,MITRE ATLAS,Defense Strategies,Implement model monitoring,"Continuously monitor AI models for signs of compromise or performance degradation",High,Model Monitoring,Medium,High,Model Compromise,"Performance monitoring, anomaly detection, and integrity checks",MITRE ATLAS,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-032,MITRE ATLAS,Defense Strategies,Implement secure model deployment,"Deploy AI models securely to prevent unauthorized access and tampering",High,Deployment Security,Medium,High,Deployment Vulnerabilities,"Secure deployment practices, access controls, and monitoring",MITRE ATLAS,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-033,Anthropic Responsible Scaling Policy,Capability Scaling,Implement capability monitoring,"Monitor AI system capabilities to detect unexpected or dangerous emergent behaviors",High,Capability Monitoring,High,High,Capability Misuse,"Capability assessment, behavior monitoring, and safety thresholds",Anthropic RSP,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-034,Anthropic Responsible Scaling Policy,Capability Scaling,Implement scaling controls,"Control AI system scaling to prevent capabilities from exceeding safety thresholds",High,Scaling Control,Very High,High,Uncontrolled Scaling,"Scaling limits, capability caps, and safety brakes",Anthropic RSP,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-035,Anthropic Responsible Scaling Policy,Safety Measures,Implement safety training,"Train AI systems with safety-focused objectives to reduce harmful outputs",High,Safety Training,High,High,Harmful Outputs,"Safety training data, harm reduction techniques, and alignment methods",Anthropic RSP,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-036,Anthropic Responsible Scaling Policy,Safety Measures,Implement safety testing,"Conduct comprehensive safety testing to identify and mitigate potential risks",High,Safety Testing,High,High,Safety Failures,"Red teaming, safety evaluation, and risk assessment",Anthropic RSP,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-037,Anthropic Responsible Scaling Policy,Risk Assessment,Implement risk evaluation,"Continuously evaluate AI system risks as capabilities evolve",High,Risk Evaluation,Medium,High,Risk Evolution,"Risk assessment frameworks, capability tracking, and safety metrics",Anthropic RSP,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z
ai-038,Anthropic Responsible Scaling Policy,Risk Assessment,Implement safety reporting,"Establish reporting mechanisms for AI safety incidents and concerns",Medium,Safety Reporting,Low,Medium,Safety Incidents,"Incident reporting, safety channels, and response procedures",Anthropic RSP,2024-01-15T10:30:00Z,2024-01-15T10:30:00Z